import pickle
import numpy as np
import sys
sys.path.append("../")
sys.path.append("../../")
sys.path.append("./")
from matplotlib import pyplot as plt
from utils import check_non_negative_integer
def psave(filename, object):
    """
    Function to save files

    :param filename: The name string you want to save 
    :param object: The object you want to save
    """
    file_write=open(filename, "wb")
    pickle.dump(object, file_write)
    file_write.close()
    return
def pload(filename):
    """
    Function to load files

    :param filename: The name string you want to load
    :return: The file
    """
    file_read=open(filename,mode="rb")
    file = pickle.load(file_read)
    file_read.close()
    return file

def view_acc(dict_train,step_size,time_edge):
    """
    Function to plot accuracy in the training

    :param data: The data generated by simulation
    :param step_size: The step size for the data
    :param time_edge: The end time you want run
    """
    # check the input
    check_non_negative_integer(step_size)
    check_non_negative_integer(time_edge)
    # plot
    steps_to_view=int(time_edge/step_size)
    x = [step_size*(i+1) for i in range (steps_to_view)]
    test=[ dict_train[v]["accuracy"][2][1]*100 for v in range (steps_to_view)]
    valid=[ max(dict_train[z]["accuracy"][1])*100 for z in range (steps_to_view)]
    train=[ max(dict_train[t]["accuracy"][0])*100 for t in range (steps_to_view)]

    lsize=2
    msize=2
    mcolor="black"
    al=0.8

    plt.figure(figsize=(15,8))
    plt.title("Accuracy VS. Time",fontdict={"family": "Times New Roman", "size": 25})
    plt.plot(x, test,color=(212/255,72/255,72/255), linewidth=lsize,marker="o",markersize=msize,markerfacecolor=mcolor,alpha=al,label="Test accuracy")
    plt.plot(x, train,"-" ,color=(0/255, 47/255, 167/255),linewidth=lsize,marker="o",markersize=msize,markerfacecolor=mcolor,alpha=al,label="Training accuracy")
    plt.plot(x, valid, "y-", linewidth=lsize,marker="o",markersize=msize,markerfacecolor=mcolor,alpha=al,label="Valid accuracy")
    plt.legend(prop={"family": "Times New Roman", "size": 20})
    plt.xticks(fontname="Times New Roman", fontsize=20)
    plt.yticks(fontname="Times New Roman", fontsize=20)
    plt.xlabel('Time',fontdict={"family": "Times New Roman", "size": 25})
    plt.ylabel('Accuracy',fontdict={"family": "Times New Roman", "size": 25})
    plt.savefig("1D_LSTM/1d_acc_{}".format(time_edge))

def most_important_features(dict_train):
    """
    Function to find location(s) of top 1 important feature(s)

    :param dict_train: The dict_train result generated by simulation
    :return: the location list indicating the most important feature
    """

    adrops = []
    min_dict={}
    num=0
    for run in range(len(dict_train)):
    #     plt.figure()
        adrop = dict_train[run]["mltsa"] # (200,72)
    #     print(np.array(adrop).shape) # (200,72)
        mean = np.mean(adrop, axis=0) # (72,)
        adrops.append(mean)
        time_mean_adrops=np.mean(np.array(adrops),axis=0)# (73,)
    #     print(time_mean_adrops.shape)
        min_feature=np.min(time_mean_adrops)
        location=np.where(time_mean_adrops==min_feature)[0]
        min_dict[num]=location
        num+=1
    return min_dict
# min_dict=most_important_features(dict_train)


def dots_plot_most_important_features(dict_train):
    """
    Function to plot top one feature(s) at each time

    :param dict_train: The dict_train result generated by simulation

    """
    min_dict=most_important_features(dict_train)
    plt.figure(figsize=(15,10))
    plt.title("Location of the Worst Accuracy Droped Features VS. Time",x=0.5,y=1)
    for time in range(len(min_dict)):
        plt.scatter([step_size*list(min_dict.keys())[time]+step_size]*min_dict[time].shape[0],min_dict[time])
    plt.ylabel("Feature Location")
    plt.xlabel("Time")
    plt.savefig("1D_LSTM/dots_plot_most_important_features.png")


def MLTSA_Plot(FR, dataset_og, pots, errorbar=True):
    """

    Wrapper for plotting the results from the Accuracy Drop procedure

    :param FR: Values from the feature reduction
    :param dataset_og: Original dataset object class used for generating the data
    :param pots: Original potentials object class used for generating the data
    :param errorbar: Flag for including or not including the errobars in case of using replicas.
    :return:

    """
    from matplotlib.colors import LinearSegmentedColormap
    import matplotlib as mpl
    # Fetching info
    std = np.std(FR, axis=0, ddof=1) * 100
    dat = np.mean(FR, axis=0) * 100
    coefs = dataset_og.mixing_coefs
    coefs = np.array(coefs).T
    combs = dataset_og.combinations
    imp_id = pots.relevant_id

    # Getting the correlated features
    cor_feats = []
    for n, idx in enumerate(combs[:len(dat)]):
        if imp_id in idx:
            cor_feats.append(n)

    # Calculating Correlation relation
    correlations = []
    for n, f in enumerate(cor_feats):
        correlation = coefs[f][np.where(np.array(combs[f]) == imp_id)[0][0]] / np.sum(coefs[f]) * 100
        correlations.append(correlation)

    plt.figure(figsize=(10, 4))
    plt.title("Feature Reduction")
    plt.plot(dat, "-o", color="black", marker="s")

    for correlated_feat, corr in zip(cor_feats, correlations):
        rgb = ((corr * 2.55) / 255, 0, 1 - (corr * 2.55) / 255)
        plt.plot(correlated_feat, dat[correlated_feat], "X", markersize=10, color=rgb)
        if errorbar == True:
            plt.errorbar(correlated_feat, dat[correlated_feat], yerr=std[correlated_feat],
                         capsize=5, linestyle="None", marker="^", color="black")
        if corr > 10:
            plt.text(correlated_feat + 6, dat[correlated_feat] - 0.005, "{:.2f}".format(corr),
                     bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'),
                     fontstyle="italic", fontweight="medium"
                     )
    plt.ylabel("Accuracy (%)")
    plt.xlabel("#Feature")
    plt.savefig("1D_LSTM/adrop_correlation.png")

    #"""Code for the colorbar below"""
    rgb1 = (0, 0, 1)
    rgb2 = (1, 0, 0)
    cmap_name = "corr"
    cmap = LinearSegmentedColormap.from_list(cmap_name, [rgb1, rgb2], N=100)
    fig, ax = plt.subplots(figsize=(6, 1))
    fig.subplots_adjust(bottom=0.5)
    norm = mpl.colors.Normalize(vmin=0, vmax=100)
    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),
                        cax=ax, orientation='horizontal', label='Correlation to DW potential (%)')
    
    #fig.show()

    return
if __name__ == '__main__':
    # load data
    n_simulations,step_size,tot_time_frame,n_features=pload("1D_LSTM/sim_argument.list")
    n_step=tot_time_frame/step_size
    dict_train=pload("1D_LSTM/results.dict")
    oneD_dataset, pots=pload("1D_LSTM/1dmodel.bin")

    # view accuracy in the training
    view_acc(dict_train,step_size,200)#last parameter is the time of edge you want to see, you can change it if you want. Make sure the corresponding model is included in the folder, or you have to generate new data.
    # view the important feature at each time
    dots_plot_most_important_features(dict_train)
    # view the accuracy drop and the correlation coefficient
    adrop=[]
    for i in range(len(dict_train)):
        adrop.append(dict_train[i]["mltsa"])
    adrop_time = 200 # the time to view mltsa, you can change it if you want. Make sure the corresponding model is included in the folder, or you have to generate new data.
    check_non_negative_integer(adrop_time)# check the input
    MLTSA_Plot(adrop[int(adrop_time/20-1)], oneD_dataset, pots, errorbar=False)
    print("--1D results have been plot--")