from ast import arguments
import sys
sys.path.append("../")
from TwoD_pot_data import *
from matplotlib import pyplot as plt
import seaborn as sns
import scipy.io as sio
import numpy as np
from sklearn.cluster import DBSCAN
import pickle

#We will start with the basic LSTM ("Vanilla")
# from MLTSA_tensorflow import TF_2_LSTM_custom as TF_2_LSTM
# Import the necessary libraries and modified bit of code
# from MLTSA_datasets.OneD_pot.OneD_pot_data import potentials
# from MLTSA_datasets.OneD_pot.OneD_pot_data import dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
# from MLTSA_tensorflow import TF_2_LSTM
import TF_2_MLP_custom as TF_2_MLP
import TF_2_LSTM_custom as TF_2_LSTM
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
from tqdm import tqdm
import time
from multiprocessing import Pool

def PrepareData(data, ans, time_frame, mode="Normal"):
    """

    Small wrapper that prepares the data inputted from the dataset object as the correct format to use on the ML
    approach.

    :param data: (list) Data simulation generated from the dataset.
    :param ans: (list) Labels of the outcome from the simulations
    :param time_frame: (list) [start_frame_range, end_frame_range] Values for the range of frames/steps to keep for
        the final data, this allows to select a particular amount from the trajectories.
    :param mode: (str) Wether to use the real value of the relevant potential as a last feature or not. "Normal"
        means using it.
    :return: (list) List containing the data as (X, Y) being X the simulation data as the mixed trajectories and
        Y as the labelled outcomes for each frame.

    """
    X = data[:, :, time_frame[0]: time_frame[1]]
    X = np.concatenate(X, axis=1).T
    Y = np.ones(len(X)).astype(str)

    for n, answer in enumerate(ans):
        frames = time_frame[1] - time_frame[0]
        tmp_ans = np.ones(frames).astype(str)
        tmp_ans[:] = answer
        Y[n * frames:n * frames + frames] = tmp_ans

    if mode == "Normal":
        pass
    elif mode == "Rigged":
        X = X[:, :-1]

    return X, Y

def MLTSA(data, ans, model, drop_mode="Average", data_mode="Normal"):
    """

    Function to apply the Machine Learning Transition State Analysis to a given training dataset/answers and trained
    model. It calculates the Gloabl Means and re-calculates accuracy for predicting each outcome.

    :param data: Training data used for training the ML model. Must have shape (samples, features)
    :type data: list
    :param ans: Outcomes for each sample on "data". Shape must be (samples)
    :type ans: list
    :param model:
    :param drop_mode:
    :param data_mode:
    :return: list

    """
    ans_list = [0, 1]

    if data_mode == "Rigged":
        data = data[:, :-1, :]

    # Calculating the global means
    means_per_sim = np.mean(data, axis=0)
    gmeans = np.mean(means_per_sim, axis=0)
    temp_sim_data = np.copy(data)
    
    # Swapping the values and predicting for the FR
    FR = []
    for y, data in tqdm(enumerate(temp_sim_data)):
        mean_sim = []
        for n, mean in enumerate(gmeans):
            tmp_dat = np.copy(data)
            #print(tmp_dat.shape)
            tmp_dat[:, n] = mean
            #print(tmp_dat)
            yy = model(np.array([tmp_dat]),training =False)
            yy = ans_list[np.argmax(yy)]
            res = np.array(yy) == np.array(ans[y])
            mean_sim.append(res)
        FR.append(mean_sim)

    return FR

def loop_train(data,labels,step_size,time_frame,sim_type,n_CPU,adrop_switch=True):
    """
    Function to apply the Machine Learning train machine learning for predicting unbinding simulation result, and do MLTSA 

    :param data: The data generated by simulation
    :param labels: The label generated by simulation    
    :param step_size: The step size gap you want run
    :type step_size: Integer
    :param time_frame: The Running time step you want 
    :param dataset: The dataset generated by simulation
    :param sim_type: name string of the model type 
    :param n_CPU: how many cpu you want to use
    :param adrop_switch: the switch to run mltsa
    :return: a dict contains time frame, model, loss, accuracy, mltsa, result
    """

    # save the intermediate variable
    accuracy_list =[]
    dict_train = {}
    
    n_step=int(time_frame/step_size)
    

    for i in range(n_step):
        edge= step_size*(i+1)
        results={}
        # for loop from 10 to 500
        time_frame = [0, edge]
        n_steps =  int(time_frame[1] - time_frame[0])
        n_features = data.shape[2]

        LSTM = TF_2_LSTM.build_LSTM(n_steps, n_features, n_labels=2,type=sim_type).model

        X_train, X_test, y_train, y_test = train_test_split(data[:,time_frame[0]:time_frame[1],:], labels, test_size=0.3, random_state=42)

        #We will convert IN and OUT to numerical labels
        encoder = OneHotEncoder()
        Y_train = encoder.fit_transform(y_train.reshape(len(y_train), 1)).toarray()
        Y_test = encoder.fit_transform(y_test.reshape(len(y_test),1)).toarray()

        LSTM_log=LSTM.fit(X_train, Y_train, epochs=1000, verbose=1, validation_split=0.2, 
                            callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=1e-8, restore_best_weights=True, patience=5)])# ,batch_size=(time_frame[1]-time_frame[0])
        # training log
        loss  = LSTM_log.history["loss"]
        val_loss = LSTM_log.history["val_loss"]
        acc_train = LSTM_log.history["accuracy"]
        acc_val = LSTM_log.history["val_accuracy"]
        
        # evaluate result
        acc_eval = LSTM.evaluate(X_test, Y_test, verbose=1)
        print("For 0 to ",edge , ", we achieved", acc_eval[1]*100, "% accuracy on Validation and ", max(acc_train)*100, "% accuracy on Training")
        
        # Adrop on 
        if adrop_switch == True:
            # data for Adrop
            dummy_data = np.random.rand(30,edge, 20)
            dummy_data[:,:,2] = data[:30, time_frame[0]:time_frame[1] , -1]
            # Time for MLTSA
            #ADrop = MLTSA(data[:, :, :edge], ans, LSTM)
            st = time.time()
            #ADrop = MLTSA_multi(data[:, :, :edge], ans, LSTM, n_CPU)
            ADrop = MLTSA(data[:, time_frame[0]:time_frame[1] ], labels, LSTM,n_CPU)
            #ADrop = MLTSA(dummy_data, labels, LSTM)
            print("Took ", time.time() - st, "seconds to calculate the ADrop")

    #     dict_train[i] = [loss, val_loss, acc_train, acc_val, ADrop]
        accuracy_list.append([acc_eval[1]*100, max(LSTM_log.history["accuracy"])*100])
        results["time"] = time_frame
        results["loss"] = [loss, val_loss]
        results["accuracy"] = [acc_train, acc_val, acc_eval]
        if adrop_switch == True:
            results["mltsa"] = ADrop
        LSTM.save("2D_LSTM_0to{}.model".format(edge))
        
        dict_train[i]=results
    return dict_train,accuracy_list

def MLP_train(data,labels,step_size,time_frame,sim_type,n_CPU,adrop_switch=True):
    """
    Function to apply the Machine Learning train machine learning for predicting unbinding simulation result, and do MLTSA 

    :param data: The data generated by simulation
    :param labels: The label generated by simulation    
    :param step_size: The step size gap you want run
    :type step_size: Integer
    :param time_frame: The Running time step you want 
    :param dataset: The dataset generated by simulation
    :param sim_type: name string of the model type 
    :param n_CPU: how many cpu you want to use
    :param adrop_switch: the switch to run mltsa
    :return: a dict contains time frame, model, loss, accuracy, mltsa, result
    """
    # save the intermediate variable
    accuracy_list =[]
    dict_train = {}
    
    n_step=int(time_frame/step_size)
    

    for i in range(n_step):
        edge= step_size*(i+1)
        results={}
        # for loop from 
        time_frame = [edge-step_size, edge]
        n_steps =  int(time_frame[1] - time_frame[0])
        n_features = data.shape[1]

        MLP = TF_2_MLP.build_MLP(n_steps, n_features, n_labels=2,type=sim_type).model
        
        X, Y = PrepareData(data, labels, time_frame, mode="Normal")

        # X_train, X_test, y_train, y_test = train_test_split(data[:,time_frame[0]:time_frame[1],:], labels, test_size=0.3, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)


        #We will convert IN and OUT to numerical labels
        encoder = OneHotEncoder()
        Y_train = encoder.fit_transform(y_train.reshape(len(y_train), 1)).toarray()
        Y_test = encoder.fit_transform(y_test.reshape(len(y_test),1)).toarray()

        MLP_log=MLP.fit(X_train, Y_train, epochs=1000, verbose=1, validation_split=0.2, 
                            callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=1e-8, restore_best_weights=True, patience=5)])# ,batch_size=(time_frame[1]-time_frame[0])
        # training log
        loss  = MLP_log.history["loss"]
        val_loss = MLP_log.history["val_loss"]
        acc_train = MLP_log.history["accuracy"]
        acc_val = MLP_log.history["val_accuracy"]
        
        # evaluate result
        acc_eval = MLP.evaluate(X_test, Y_test, verbose=1)
        print("For 0 to ",edge , ", we achieved", acc_eval[1]*100, "% accuracy on Validation and ", max(acc_train)*100, "% accuracy on Training")
        
        # Adrop on 
        if adrop_switch == True:
            # data for Adrop
            dummy_data = np.random.rand(30,edge, 20)
            dummy_data[:,:,2] = data[:30, time_frame[0]:time_frame[1] , -1]
            # Time for MLTSA
            #ADrop = MLTSA(data[:, :, :edge], ans, LSTM)
            st = time.time()
            #ADrop = MLTSA_multi(data[:, :, :edge], ans, LSTM, n_CPU)
            ADrop = MLTSA(data[:, time_frame[0]:time_frame[1] ], labels, MLP,n_CPU)
            #ADrop = MLTSA(dummy_data, labels, LSTM)
            print("Took ", time.time() - st, "seconds to calculate the ADrop")

    #     dict_train[i] = [loss, val_loss, acc_train, acc_val, ADrop]
        accuracy_list.append([acc_eval[1]*100, max(MLP_log.history["accuracy"])*100])
        results["time"] = time_frame
        results["loss"] = [loss, val_loss]
        results["accuracy"] = [acc_train, acc_val, acc_eval]
        if adrop_switch == True:
            results["mltsa"] = ADrop
        MLP.save("2D_MLP_0to{}.model".format(edge))
        
        dict_train[i]=results
    return dict_train,accuracy_list


def psave(filename, object):
    """
    Function to save files

    :param filename: The name string you want to save 
    :param object: The object you want to save
    """
    file_write=open(filename, "wb")
    pickle.dump(object, file_write)
    file_write.close()
    return
def pload(filename):
    """
    Function to load files

    :param filename: The name string you want to load
    :return: The file
    """
    file_read=open(filename,mode="rb")
    file = pickle.load(file_read)
    file_read.close()
    return file

if __name__=="__main__":

    load_data =False# True：using the current data; False: generating new data
    if load_data == True:             
        raw_s2,dp_s2,p_10,data_s2,label_s2,projs= pload("data.list")
        n_simulation=200
        n_feature=72
        sim_type="s2"
    else:
        n_simulation=200 # number of simulations
        n_feature=72 # number of features
        sim_type='s2'# simulateion type, string, option: s2,s3,z
        raw_s2 = generate_traj(sim_type, number=int(n_simulation*2), visual=True)# s2,s3,z2,z3
        dp_s2 = data_processor(sim_type)
        data_s2, label_s2 = data_process_full(dp_s2, raw_s2, int(n_simulation/2), True)
        
        p_10 = Projector(n_feature)
        p_10.coeff=np.linspace(0,2*np.pi,num=n_feature)
        p_10.show_axis()
        projs = p_10.batch_rotation(data_s2)

    data=[raw_s2,dp_s2,p_10,data_s2,label_s2,projs]
    psave("data.list",data)
    print("--Generating data finished--")

    # projsT = projs.transpose(0,2,1)
    projsT=projs.reshape(projs.shape[0],projs.shape[2],projs.shape[1])
  

    # simulation arguments setting
    n_CPU=8
    step_size=20
    tot_time_frame=500
    model_type="vanilla" # one option for MLP:"vanilla"; three options for LSTM:"vanilla","stacked","bidirectional"

    sim_arguments=[n_simulation,n_feature,sim_type,model_type,step_size,tot_time_frame]
    psave("sim_arguments.list",sim_arguments)

    switch=False # a swith to turn on the MLTSA, True is on, False is off

    # MLP and LSTM training: Which one you want to train, just uncomment it
    # dict_train,accuracy_list=MLP_train(projs,label_s2,step_size,tot_time_frame,model_type,n_CPU,switch)
    dict_train,accuracy_list=loop_train(projsT,label_s2,step_size,tot_time_frame,model_type,n_CPU,switch)# LSTM models training

    # save the results
    print("--Training over--")
    psave("dict_train.dict",dict_train)
    psave("accuracy_list.list",accuracy_list)
    print("--Result saved--")
    
