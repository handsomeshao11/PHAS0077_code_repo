"""
Author: Pedro J. Buigues and Juexi Shao
This snippet is a script that runs on MLTSA for the implementation of the LSTM and MLP and test of the importance of features.
"""
# Import the necessary libraries and modified bit of code
from MLTSA_datasets.OneD_pot.OneD_pot_data import potentials
from MLTSA_datasets.OneD_pot.OneD_pot_data import dataset
from sklearn.preprocessing import OneHotEncoder
import TF_2_MLP_custom as TF_2_MLP
import TF_2_LSTM_custom as TF_2_LSTM
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
import numpy as np
from tqdm import tqdm
import pickle
import time
from multiprocessing import Pool

# Modified functions to use in this script (because of the LSTM) - Should move them into a module soon

def MLTSA(data, ans, model, drop_mode="Average", data_mode="Normal"):
    """

    Function to apply the Machine Learning Transition State Analysis to a given training dataset/answers and trained
    model. It calculates the Gloabl Means and re-calculates accuracy for predicting each outcome.

    :param data: Training data used for training the ML model. Must have shape (samples, features)
    :type data: list
    :param ans: Outcomes for each sample on "data". Shape must be (samples)
    :type ans: list
    :param model:
    :param drop_mode:
    :param data_mode:
    :return: list

    """
    ans_list = ["IN", "OUT"]

    if data_mode == "Rigged":
        data = data[:, :-1, :]

    # Calculating the global means
    means_per_sim = np.mean(data, axis=0)
    gmeans = np.mean(means_per_sim, axis=1)
    temp_sim_data = np.copy(data)

    # Swapping the values and predicting for the FR
    FR = []
    for y, data in tqdm(enumerate(temp_sim_data)):
        mean_sim = []
        for n, mean in enumerate(gmeans):
            tmp_dat = np.copy(data)
            tmp_dat[n, :] = mean
            yy = model(np.array([tmp_dat.T]),training =False)
            yy = ans_list[np.argmax(yy)]
            res = np.array(yy) == np.array(ans[y])
            mean_sim.append(res)
        FR.append(mean_sim)

    return FR

def psave(filename, object):
    """
    Function to save files

    :param filename: The name string you want to save 
    :param object: The object you want to save
    """
    file_write=open(filename, "wb")
    pickle.dump(object, file_write)
    file_write.close()
    return
def pload(filename):
    """
    Function to load files

    :param filename: The name string you want to load
    :return: The file
    """
    file_read=open(filename,mode="rb")
    file = pickle.load(file_read)
    file_read.close()
    return file

def LSTM_Loop(step_size, n_frames, dataset, data, ans,type_model, n_CPU, mltsa_switch=True):
    """
    Function to apply the Machine Learning train machine learning for predicting unbinding simulation result, and do MLTSA 

    :param step_size: The step size gap you want run
    :type step_size: Integer
    :param n_frames: The Running time step you want 
    :param dataset: The dataset generated by simulation
    :param data: The data generated by simulation
    :param ans: The label generated by simulation
    :param type_model: name string of the model type 
    :param n_CPU: how many cpu you want to use
    :param mltsa_switch: the switch to run mltsa
    :return: a dict contains time frame, model, loss, accuracy, mltsa, result
    """

    dict_train = {}

    steps = int(n_frames/step_size)

    edge = 0
    for i in range(steps):

        results = {}
        # Prepare it for training
        edge += step_size
        time_frame = [0, edge]
        X, Y = dataset.PrepareData(data, ans, time_frame, mode="Normal")
        X = X.reshape(int(X.shape[0] / (time_frame[1] - time_frame[0])), int(time_frame[1] - time_frame[0]), X.shape[1])

        X_val, Y_val = dataset.PrepareData(data_val, ans_val, time_frame, mode="Normal")
        X_val = X_val.reshape(int(X_val.shape[0] / (time_frame[1] - time_frame[0])), int(time_frame[1] - time_frame[0]),
                              X_val.shape[1])

        # We will convert IN and OUT to numerical labels
        encoder = OneHotEncoder()
        Y = encoder.fit_transform(ans.reshape(len(ans), 1)).toarray()
        Y_val = encoder.fit_transform(ans_val.reshape(len(ans_val), 1)).toarray()

        # We will start with the basic LSTM ("Vanilla")
        LSTM = TF_2_LSTM.build_LSTM((time_frame[1] - time_frame[0]), n_features, 2,type_model).model
        LSTM_log = LSTM.fit(X, Y, epochs=1000, batch_size=(time_frame[1] - time_frame[0]), verbose=1,
                            validation_split=0.2,
                            callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=1e-8, restore_best_weights=True,
                                                     patience=5)])

        # accuracy, and max accuracy
        final_val_acc = LSTM.evaluate(X_val, Y_val, verbose=1)
        print("For 0 to ", edge, ", we achieved", final_val_acc[1] * 100, "% accuracy on Validation and ",
              max(LSTM_log.history["accuracy"]) * 100, "% accuracy on Training")

        if mltsa_switch == True:
            # Time for MLTSA
            #ADrop = MLTSA(data[:, :, :edge], ans, LSTM)
            st = time.time()
            #ADrop = MLTSA_multi(data[:, :, :edge], ans, LSTM, n_CPU)
            ADrop = MLTSA(data[:, :, :edge], ans, LSTM)
            print("Took ", time.time() - st, "seconds to calculate the ADrop")  

        # loss log
        loss = LSTM_log.history["loss"]
        val_loss = LSTM_log.history["val_loss"]
        acc_train = LSTM_log.history["accuracy"]
        acc_val = LSTM_log.history["val_accuracy"]

        results["time"] = time_frame
        results["model"] = LSTM
        results["loss"] = [loss, val_loss]
        results["accuracy"] = [acc_train, acc_val, final_val_acc]

        if mltsa_switch == True:
            results["mltsa"] = ADrop 

        dict_train[i] = results

    return dict_train

def MLTSA_1(data, ans, model, drop_mode="Average", data_mode="Normal"):
    """

    Function to apply the Machine Learning Transition State Analysis to a given training dataset/answers and trained
    model. It calculates the Gloabl Means and re-calculates accuracy for predicting each outcome.

    :param data: Training data used for training the ML model. Must have shape (samples, features)
    :type data: list
    :param ans: Outcomes for each sample on "data". Shape must be (samples)
    :type ans: list
    :param model:
    :param drop_mode:
    :param data_mode:
    :return: list

    """

    ans_list = ["IN", "OUT"]

    if data_mode == "Rigged":
        data = data[:, :-1, :]

    # Calculating the global means
    means_per_sim = np.mean(data.T, axis=0)
    gmeans = np.mean(means_per_sim, axis=1)
    #print(gmeans.shape)
    temp_sim_data = np.copy(data)
    #print(temp_sim_data.shape)

    # Swapping the values and predicting for the FR
    FR = []
    for y, data in tqdm(enumerate(temp_sim_data)):
        mean_sim = []
        for n, mean in enumerate(gmeans):
            tmp_dat = np.copy(data)
            #print(tmp_dat.shape)
            tmp_dat[n ,:] = mean
            #print(tmp_dat.T.shape)
            # yy = model.predict(tmp_dat.T)
            # res = yy == ans[y]
            yy = model(tmp_dat.T,training=False)
            yy = np.mean(yy, axis=0)
            yy = ans_list[np.argmax(yy)]
            res = np.array(yy) == np.array(ans[y])
            mean_sim.append(res)
        FR.append(mean_sim)

    return FR


def MLP_Loop(step_size, n_frames, dataset, data, ans, type_model,n_CPU):
    """
    Function to apply the Machine Learning train machine learning for predicting unbinding simulation result, and do MLTSA 

    :param step_size: The step size gap you want run
    :type step_size: Integer
    :param n_frames: The Running time step you want 
    :param dataset: The dataset generated by simulation
    :param data: The data generated by simulation
    :param ans: The label generated by simulation
    :param type_model: name string of the model type 
    :param n_CPU: how many cpu you want to use
    :return: a dict contains time frame, model, loss, accuracy, mltsa, result
    """

    dict_train = {}

    steps = int(n_frames/step_size)

    edge = 0
    for i in range(steps):

        results = {}
        # Prepare it for training
        edge += step_size
        time_frame = [edge-step_size, edge]
        print("ok")
        X, Y = dataset.PrepareData(data, ans, time_frame, mode="Normal")

        # X = X.reshape(int(X.shape[0] / (time_frame[1] - time_frame[0])), int(time_frame[1] - time_frame[0]), X.shape[1])
 

        X_val, Y_val = dataset.PrepareData(data_val, ans_val, time_frame, mode="Normal")
        # X_val = X_val.reshape(int(X_val.shape[0] / (time_frame[1] - time_frame[0])), int(time_frame[1] - time_frame[0]),
        #                       X_val.shape[1])
        # We will convert IN and OUT to numerical labels

        from sklearn.preprocessing import OneHotEncoder
        encoder = OneHotEncoder()
        Y = encoder.fit_transform(Y.reshape(len(Y), 1)).toarray()
        Y_val = encoder.fit_transform(Y_val.reshape(len(Y_val),1)).toarray()

        # encoder = OneHotEncoder()
        # Y = encoder.fit_transform(ans.reshape(len(ans), 1)).toarray()
        # Y_val = encoder.fit_transform(ans_val.reshape(len(ans_val), 1)).toarray()

        # We will start with the basic LSTM ("Vanilla")
        MLP = TF_2_MLP.build_MLP((time_frame[1] - time_frame[0]), n_features, 2,type_model).model
        MLP_log = MLP.fit(X, Y, epochs=1000, batch_size=(time_frame[1] - time_frame[0]), verbose=1,
                            validation_split=0.2,
                            callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=1e-8, restore_best_weights=True,
                                                     patience=20)])

        # accuracy, and max accuracy
        final_val_acc = MLP.evaluate(X_val, Y_val, verbose=1)
        print("For 0 to ", edge, ", we achieved", final_val_acc[1] * 100, "% accuracy on Validation and ",
              max(MLP_log.history["accuracy"]) * 100, "% accuracy on Training")

        # Time for MLTSA
        #ADrop = MLTSA——MLP(data[:, :, :edge], ans, LSTM)
        st = time.time()
        #ADrop = MLTSA_multi(data[:, :, :edge], ans, LSTM, n_CPU)
        ADrop = MLTSA_1(data[:, :, time_frame[0]:time_frame[1]], ans, MLP)
        print("Took ", time.time() - st, "seconds to calculate the ADrop")

        # loss log
        loss = MLP_log.history["loss"]
        val_loss = MLP_log.history["val_loss"]
        acc_train = MLP_log.history["accuracy"]
        acc_val = MLP_log.history["val_accuracy"]

        results["time"] = time_frame
        results["model"] = MLP
        results["loss"] = [loss, val_loss]
        results["accuracy"] = [acc_train, acc_val, final_val_acc]
        results["mltsa"] = ADrop

        dict_train[i] = results

    return dict_train


if __name__ == '__main__':
    load_data = False# True：using the current data; False: generating new data

    if load_data==True:
        data,ans,data_val, ans_val,oneD_dataset=pload("1D_data.list")
        n_simulations,step_size,time_frame,n_features=pload("1D_sim_argument.list")
    else:    
        #This sets the potentials, don't re-run
        total_n_pots = 25
        n_DW = 5
        relevant_DW_n = 2
        #After defining the desired parameters we define the potentials accordingly
        pots = potentials(total_n_pots, n_DW, relevant_DW_n)
        # This creates the first dataset of data.
        # It creates the mixing coefficients don't re-run
        n_features = 72
        degree_of_mixing = 2
        #We specified the number of features wanted and how much they will mix
        oneD_dataset = dataset(pots, n_features, degree_of_mixing)

        #Generate the trajectories
        n_simulations = 200
        n_times = 1000
        data, ans = oneD_dataset.generate_linear(n_simulations, n_times)
        data_val, ans_val = oneD_dataset.generate_linear(int(n_simulations/2), n_times)

        
    data_list=[data, ans,data_val, ans_val,oneD_dataset]
    
    #Now we run the function for the accuracy at different times.
    step_size = 20 # Size of the steps to take
    n_CPU = 2 # Number of parallel processes to start
    time_frame = 40 # The time of duration we want to run, you can set it as 1000 best
    model_type="vanilla" # one option for MLP:"vanilla"; three options for LSTM:"vanilla","stacked","bidirectional"
    switch = False # the switch to run the mltsa

    # MLP and LSTM training: Which one you want to train, just uncomment it
    # results = MLP_Loop(step_size, time_frame, oneD_dataset, data, ans,model_type, n_CPU) # Two option function: MLP_Loop and LSTM_Loop 
    results =LSTM_Loop(step_size, time_frame, oneD_dataset, data, ans,model_type, n_CPU,switch) 
    print("--Training over--")
    sim_argument=[n_simulations,step_size,time_frame,n_features]


    """ We need to save them to folders, because the models can't be pickled, we will not
     always have to save them, so the additional step is in case we want to save the model."""
    for k in results:
        model = results[k]["model"]
        del results[k]["model"]
        model.save("1D_model_0to{}.model".format((k+1)*step_size))

    #We save the dictionary of the results in a pickle. We cannot save the dictionary with the model inside.
    psave("data.list",data_list)

    psave("sim_argument.list",sim_argument)    

    psave("results.dict", results)

    psave("1dmodel.bin", [oneD_dataset, pots])

    print("--Result saved--")